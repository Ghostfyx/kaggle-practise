{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# pandas一些属性设置\n",
    "pd.set_option('max_colwidth',20000)\n",
    "pd.set_option('display.width',200)\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "# matlab支持汉字\n",
    "mpl.rcParams[\"font.family\"]=\"sans-serif\"\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data begin\n    Age Cabin Embarked     Fare                                                 Name  Parch  PassengerId  Pclass     Sex  SibSp  Survived            Ticket\n0  22.0   NaN        S   7.2500                              Braund, Mr. Owen Harris      0            1       3    male      1       0.0         A/5 21171\n1  38.0   C85        C  71.2833  Cumings, Mrs. John Bradley (Florence Briggs Thayer)      0            2       1  female      1       1.0          PC 17599\n2  26.0   NaN        S   7.9250                               Heikkinen, Miss. Laina      0            3       3  female      0       1.0  STON/O2. 3101282\n3  35.0  C123        S  53.1000         Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4       1  female      1       1.0            113803\n4  35.0   NaN        S   8.0500                             Allen, Mr. William Henry      0            5       3    male      0       0.0            373450\n"
     ]
    }
   ],
   "source": [
    "print('read data begin')\n",
    "train_file_path = 'data/Titanic/train.csv'\n",
    "test_file_path = 'data/Titanic/test.csv'\n",
    "train_data = pd.read_csv(train_file_path, header=0)\n",
    "test_data = pd.read_csv(test_file_path, header=0)\n",
    "df = pd.concat([train_data, test_data], ignore_index=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理缺省值\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 12 columns):\nAge            1046 non-null float64\nCabin          295 non-null object\nEmbarked       1307 non-null object\nFare           1308 non-null float64\nName           1309 non-null object\nParch          1309 non-null int64\nPassengerId    1309 non-null int64\nPclass         1309 non-null int64\nSex            1309 non-null object\nSibSp          1309 non-null int64\nSurvived       891 non-null float64\nTicket         1309 non-null object\ndtypes: float64(3), int64(4), object(5)\nmemory usage: 122.8+ KB\n--**----**----**----**----**----**----**----**----**----**--\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\nPassengerId    418 non-null int64\nPclass         418 non-null int64\nName           418 non-null object\nSex            418 non-null object\nAge            332 non-null float64\nSibSp          418 non-null int64\nParch          418 non-null int64\nTicket         418 non-null object\nFare           417 non-null float64\nCabin          91 non-null object\nEmbarked       418 non-null object\ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "print('开始处理缺省值')\n",
    "df.info()\n",
    "print('--**--'*10)\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 缺省值为：Age,Cabin,Embarked,Fare,Survived，其中Survived的缺省值可以忽略\n",
    "train_data_index = train_data.shape[0]\n",
    "# Cabin的缺省值过多\n",
    "df['Cabin'] = df['Cabin'].fillna(value='U0')\n",
    "# Embarked使用众数填充,对于分类变量，使用众数或许比平均值更好\n",
    "df['Embarked'] = df['Embarked'].fillna(value=df['Embarked'].mode().values[0])\n",
    "df['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age Cabin Embarked  Fare                Name  Parch  PassengerId  Pclass   Sex  SibSp  Survived Ticket\n1043  60.5    U0        S   NaN  Storey, Mr. Thomas      0         1044       3  male      0       NaN   3701\n"
     ]
    }
   ],
   "source": [
    "# Fare的缺省值根据社会等级的平均票价决定\n",
    "print(df[df['Fare'].isnull()])\n",
    "df['Fare'] = df[['Fare','Pclass']].groupby('Pclass')['Fare'].transform(lambda x : x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6)\n(891, 6)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-964f5ff3d895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredict_ages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_isnull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mpredict_ages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpredict_ages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Administrator\\venv\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Administrator\\venv\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    362\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Administrator\\venv\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    378\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32mC:\\Users\\Administrator\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    575\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 577\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "'''\n",
    "使用回归 随机森林等模型来预测缺失属性的值。因为Age在该数据集里是一个相当重要的特征\n",
    "所以保证一定的缺失值填充准确率是非常重要的，对结果也会产生较大影响。一般情况下，会使用数据完整的条目作为模型的训练集，以此来预测缺失值。\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "train_data = df.iloc[:train_data_index, :]\n",
    "age_train = train_data[['Age','Survived','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "age_isnull = age_train[age_train['Age'].isnull()]\n",
    "age_notnull = age_train[age_train['Age'].notnull()]\n",
    "X = age_notnull.iloc[:, 1:]\n",
    "y = age_notnull.iloc[:, 0]\n",
    "print(age_isnull.shape)\n",
    "print(age_notnull.shape)\n",
    "rdf = RandomForestRegressor(n_estimators=1000, n_jobs=-1)\n",
    "rdf.fit(X, y)\n",
    "predict_ages = rdf.predict(age_isnull.iloc[:, 1:])\n",
    "predict_ages\n",
    "train_data.loc[train_data['Age'].isnull(), 'Age']= predict_ages\n",
    "print(train_data['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始数据可视化处理\n生存关系的整体分布\n"
     ]
    }
   ],
   "source": [
    "print('开始数据可视化处理')\n",
    "print('生存关系的整体分布')\n",
    "#DataFrame.plot( )画图函数\n",
    "train_data['Survived'].value_counts().plot(autopct = '%1.2f%%', kind='pie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分析性別与生存之间的关系\n"
     ]
    }
   ],
   "source": [
    "print(\"分析性別与生存之间的关系\")\n",
    "train_data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "船舱等级和生存的关系\n"
     ]
    }
   ],
   "source": [
    "print(\"船舱等级和生存的关系\")\n",
    "train_data[['Pclass','Survived']].groupby(['Pclass']).mean().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姓名和生存的关系\n"
     ]
    }
   ],
   "source": [
    "print(\"姓名和生存的关系\")\n",
    "# 对姓名只取称呼部门，因为称呼决定了社会关系等。。。\n",
    "train_data['Title'] = train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "pd.crosstab(train_data['Title'], train_data['Sex'])\n",
    "a = train_data[['Title','Survived']].groupby(['Title']).mean()\n",
    "a.plot(kind='bar')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "年龄和生存的关系\n各个年龄分布的直方图\n80.0\n"
     ]
    }
   ],
   "source": [
    "print('年龄和生存的关系')\n",
    "print('各个年龄分布的直方图')\n",
    "print(np.max(train_data['Age']))\n",
    "plt.figure(figsize=(8,10))\n",
    "train_data['Age'].hist(bins=70)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Num')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (18, 8))\n",
    "# 琴式图\n",
    "sns.violinplot(\"Pclass\", \"Age\", hue=\"Survived\", data=train_data, split=True, ax=ax[0])\n",
    "ax[0].set_title('Pclass and Age vs Survived')\n",
    "ax[0].set_yticks(range(0, 110, 10))\n",
    "\n",
    "sns.violinplot(\"Sex\", \"Age\", hue=\"Survived\", data=train_data, split=True, ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Survived')\n",
    "ax[1].set_yticks(range(0, 110, 10))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data.boxplot(column='Age', showfliers=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train_data, hue=\"Survived\",aspect=4)\n",
    "# kdeplot核密度估计图\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train_data['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis1 = plt.subplots(1,1,figsize=(18,4))\n",
    "train_data[\"Age_int\"] = train_data[\"Age\"].astype(int)\n",
    "average_age = train_data[[\"Age_int\", \"Survived\"]].groupby(['Age_int'],as_index=False).mean()\n",
    "sns.barplot(x='Age_int', y='Survived', data=average_age)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\nmean      29.653887\nstd       13.729017\nmin        0.420000\n25%       21.000000\n50%       28.000000\n75%       37.000000\nmax       80.000000\nName: Age, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照年龄，将乘客划分为儿童、少年、成年和老年，分析四个群体的生还情况\n",
    "split = [0, 12, 18, 65, 100]\n",
    "train_data['Age_group'] = pd.cut(train_data['Age'], bins=split)\n",
    "by_age = train_data.groupby('Age_group')['Survived'].mean()\n",
    "by_age.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "船上兄弟姐妹和配偶的数目与生存关系\n"
     ]
    }
   ],
   "source": [
    "title='SibSp relationship with Survived'\n",
    "print('船上兄弟姐妹和配偶的数目与生存关系')\n",
    "train_data[['SibSp','Survived']].groupby(['SibSp']).mean().plot.bar()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "船上父母，子女的数目与生存关系\n"
     ]
    }
   ],
   "source": [
    "title='Parch relationship with Survived'\n",
    "print('船上父母，子女的数目与生存关系')\n",
    "train_data[['Parch','Survived']].groupby(['Parch']).mean().plot.bar()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "船上亲戚的数目与生存的关系\n从图表中可以看出，若独自一人，那么其存活率比较低；但是如果亲友太多的话，存活率也会很低。\n"
     ]
    }
   ],
   "source": [
    "print('船上亲戚的数目与生存的关系')\n",
    "train_data['Family'] = train_data['Parch']+train_data['SibSp']\n",
    "train_data[['Family','Survived']].groupby(['Family']).mean().plot.bar()\n",
    "plt.show()\n",
    "print('从图表中可以看出，若独自一人，那么其存活率比较低；但是如果亲友太多的话，存活率也会很低。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "票价分布的直方图\n"
     ]
    }
   ],
   "source": [
    "print('票价分布的直方图')\n",
    "plt.figure(figsize=(8,15))\n",
    "train_data['Fare'].hist(bins=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "票价与社会阶级之间的关系\n"
     ]
    }
   ],
   "source": [
    "print('票价与社会阶级之间的关系')\n",
    "plt.figure(figsize=(8,10))\n",
    "train_data.groupby(['Pclass'])['Fare'].mean().plot.bar(width=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\nmean      32.204208\nstd       49.693429\nmin        0.000000\n25%        7.910400\n50%       14.454200\n75%       31.000000\nmax      512.329200\nName: Fare, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "船舱编号和生存之间的关系\n"
     ]
    }
   ],
   "source": [
    "print('船舱编号和生存之间的关系')\n",
    "# Cabin缺省的字段较多，先将缺省船舱编号的和非缺省船舱编码号的进行对比\n",
    "train_data['Has_Cabin'] = train_data['Cabin'].apply(lambda x : 0 if x=='U0' else 1)\n",
    "train_data[['Has_Cabin','Survived']].groupby(['Has_Cabin']).mean().plot.bar(width=0.2)\n",
    "plt.show()\n",
    "# 有船舱的人存活率更高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不同登录港口和生存之间的关系\n"
     ]
    }
   ],
   "source": [
    "print('不同登录港口和生存之间的关系')\n",
    "train_data[['Embarked','Survived']].groupby(['Embarked']).mean().plot.bar(width=0.2)\n",
    "plt.show()\n",
    "# 由上可以看出，在不同的港口上船，生还率不同，C最高，Q次之，S最低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始特征工程\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 12 columns):\nAge            1223 non-null float64\nCabin          1309 non-null object\nEmbarked       1309 non-null object\nFare           1309 non-null float64\nName           1309 non-null object\nParch          1309 non-null int64\nPassengerId    1309 non-null int64\nPclass         1309 non-null int64\nSex            1309 non-null object\nSibSp          1309 non-null int64\nSurvived       891 non-null float64\nTicket         1309 non-null object\ndtypes: float64(3), int64(4), object(5)\nmemory usage: 122.8+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "print('开始特征工程')\n",
    "# 在进行特征工程的时候，我们不仅需要对训练数据进行处理，还需要同时将测试数据同训练数据一起处理，使得二者具有相同的数据类型和数据分布。\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "首先对离散型类别变量进行处理\n开始对Embarked进行处理\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 15 columns):\nEmbarked_C     1309 non-null uint8\nEmbarked_Q     1309 non-null uint8\nEmbarked_S     1309 non-null uint8\nAge            1223 non-null float64\nCabin          1309 non-null object\nEmbarked       1309 non-null object\nFare           1309 non-null float64\nName           1309 non-null object\nParch          1309 non-null int64\nPassengerId    1309 non-null int64\nPclass         1309 non-null int64\nSex            1309 non-null object\nSibSp          1309 non-null int64\nSurvived       891 non-null float64\nTicket         1309 non-null object\ndtypes: float64(3), int64(4), object(5), uint8(3)\nmemory usage: 126.6+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "print('首先对离散型类别变量进行处理')\n",
    "# 使用one-hot编码对离散型类别进行处理\n",
    "print('开始对Embarked进行处理')\n",
    "emb_dummies_df = pd.get_dummies(df['Embarked'], prefix=df[['Embarked']].columns[0])\n",
    "df = pd.concat([emb_dummies_df, df], axis=1,)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始对性别进行处理\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 17 columns):\nSex_female     1309 non-null uint8\nSex_male       1309 non-null uint8\nEmbarked_C     1309 non-null uint8\nEmbarked_Q     1309 non-null uint8\nEmbarked_S     1309 non-null uint8\nAge            1223 non-null float64\nCabin          1309 non-null object\nEmbarked       1309 non-null object\nFare           1309 non-null float64\nName           1309 non-null object\nParch          1309 non-null int64\nPassengerId    1309 non-null int64\nPclass         1309 non-null int64\nSex            1309 non-null object\nSibSp          1309 non-null int64\nSurvived       891 non-null float64\nTicket         1309 non-null object\ndtypes: float64(3), int64(4), object(5), uint8(5)\nmemory usage: 129.2+ KB\nNone\nNone\n"
     ]
    }
   ],
   "source": [
    "print('开始对性别进行处理')\n",
    "sex_dummies_df = pd.get_dummies(df['Sex'], prefix=df[['Sex']].columns[0])\n",
    "df = pd.concat([sex_dummies_df, df], axis=1)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始对姓名进行处理\n首先对称呼进行提取\n['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n 'Sir' 'Mlle' 'Col' 'Capt' 'Countess' 'Jonkheer' 'Dona']\n0\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1309 entries, 0 to 1308\nData columns (total 24 columns):\nTitle_Master     1309 non-null uint8\nTitle_Miss       1309 non-null uint8\nTitle_Mr         1309 non-null uint8\nTitle_Mrs        1309 non-null uint8\nTitle_Officer    1309 non-null uint8\nTitle_Royalty    1309 non-null uint8\nSex_female       1309 non-null uint8\nSex_male         1309 non-null uint8\nEmbarked_C       1309 non-null uint8\nEmbarked_Q       1309 non-null uint8\nEmbarked_S       1309 non-null uint8\nAge              1223 non-null float64\nCabin            1309 non-null object\nEmbarked         1309 non-null object\nFare             1309 non-null float64\nName             1309 non-null object\nParch            1309 non-null int64\nPassengerId      1309 non-null int64\nPclass           1309 non-null int64\nSex              1309 non-null object\nSibSp            1309 non-null int64\nSurvived         891 non-null float64\nTicket           1309 non-null object\nTitle            1309 non-null object\ndtypes: float64(3), int64(4), object(6), uint8(11)\nmemory usage: 147.1+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "print('开始对姓名进行处理')\n",
    "print('首先对称呼进行提取')\n",
    "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "print(df['Title'].unique())\n",
    "print(df['Title'].isnull().sum())\n",
    "# dict.fromkeys用于创建一个新字典，以序列seq中元素做字典的键，value为字典所有键对应的初始值\n",
    "title_Dict = {}\n",
    "# 对应官员\n",
    "title_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))\n",
    "# 对应皇室成员\n",
    "title_Dict.update(dict.fromkeys(['Don', 'Sir', 'Countess', 'Dona', 'Lady'], 'Royalty'))\n",
    "# Mrs已婚女性\n",
    "title_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))\n",
    "title_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))\n",
    "title_Dict.update(dict.fromkeys(['Mr'], 'Mr'))\n",
    "# Master 未成年男少主人的称呼,相当于汉语的\"少爷\n",
    "title_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))\n",
    "df['Title'] = df['Title'].map(title_Dict)\n",
    "title_dummies_df = pd.get_dummies(df['Title'], prefix=df[['Title']].columns[0])\n",
    "df = pd.concat([title_dummies_df, df], axis=1)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始对Ticket进行处理\n数据集的长度为：1309;不同Ticket的长度为：929\n有重复的船票编号，因此可能出现家庭/团体票\n"
     ]
    }
   ],
   "source": [
    "print('开始对Ticket进行处理')\n",
    "m = df.shape[0]\n",
    "ticket_len = len(df['Ticket'].unique())\n",
    "print('数据集的长度为：%d;不同Ticket的长度为：%d'%(m,ticket_len))\n",
    "if m == ticket_len:\n",
    "    print('没有重复的船票编号')\n",
    "else:\n",
    "    print('有重复的船票编号，因此可能出现家庭/团体票')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Group_Ticket  Fare_mean  Pclass\n0             1     7.2500       3\n1             2    71.2833       1\n2             1     7.9250       3\n3             2    53.1000       1\n4             1     8.0500       3\n"
     ]
    }
   ],
   "source": [
    "# 船票编号和票价有必然关系，因此将团体票的人所付的票价与非团体票所付的票价相对比\n",
    "df['Group_Ticket'] = df[['Ticket','Fare']].groupby('Ticket').transform('count')\n",
    "# 通过Group_Ticket可以看出每个票编码的购买人数\n",
    "df['Fare_mean'] = df.groupby('Ticket')['Fare'].transform('mean')\n",
    "print(df[['Group_Ticket','Fare_mean','Pclass']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7.25000\n1    35.64165\n2     7.92500\n3    26.55000\n4     8.05000\nName: Fare, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fare'] = df['Fare']/df['Group_Ticket']\n",
    "df['Fare'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n1       1\n2       2\n3       1\n4       2\n5       2\n6       3\n7       4\n8       4\n9       3\n10      4\n11      1\n12      2\n13      4\n14      0\n15      3\n16      4\n17      3\n18      2\n19      4\n20      3\n21      3\n22      2\n23      1\n24      4\n25      4\n26      4\n27      1\n28      0\n29      0\n30      1\n31      1\n32      0\n33      2\n34      1\n35      3\n36      4\n37      2\n38      2\n39      4\n40      2\n41      2\n42      0\n43      2\n44      0\n45      2\n46      0\n47      0\n48      4\n49      2\n50      4\n51      0\n52      3\n53      3\n54      1\n55      1\n56      2\n57      4\n58      4\n59      4\n60      4\n61      1\n62      1\n63      4\n64      1\n65      4\n66      2\n67      2\n68      2\n69      2\n70      2\n71      4\n72      2\n73      4\n74      4\n75      0\n76      0\n77      2\n78      2\n79      4\n80      2\n81      2\n82      0\n83      3\n84      2\n85      2\n86      4\n87      2\n88      1\n89      2\n90      2\n91      0\n92      1\n93      4\n94      0\n95      2\n96      1\n97      1\n98      3\n99      3\n100     0\n101     0\n102     1\n103     2\n104     2\n105     0\n106     0\n107     0\n108     0\n109     2\n110     3\n111     4\n112     2\n113     2\n114     4\n115     2\n116     0\n117     2\n118     1\n119     4\n120     2\n121     2\n122     3\n123     3\n124     1\n125     4\n126     0\n127     4\n128     0\n129     4\n130     0\n131     4\n132     0\n133     3\n134     3\n135     3\n136     1\n137     1\n138     4\n139     1\n140     4\n141     0\n142     2\n143     4\n144     3\n145     2\n146     0\n147     4\n148     2\n149     3\n150     3\n151     1\n152     2\n153     4\n154     0\n155     1\n156     0\n157     2\n158     2\n159     4\n160     2\n161     0\n162     0\n163     2\n164     4\n165     4\n166     1\n167     4\n168     3\n169     4\n170     1\n171     4\n172     4\n173     2\n174     1\n175     0\n176     4\n177     1\n178     3\n179     4\n180     4\n181     3\n182     4\n183     2\n184     0\n185     1\n186     0\n187     1\n188     0\n189     0\n190     3\n191     3\n192     0\n193     2\n194     1\n195     1\n196     0\n197     2\n198     0\n199     3\n200     2\n201     4\n202     4\n203     4\n204     2\n205     4\n206     2\n207     2\n208     0\n209     1\n210     4\n211     2\n212     0\n213     3\n214     0\n215     1\n216     2\n217     3\n218     1\n219     2\n220     2\n221     3\n222     2\n223     0\n224     1\n225     2\n226     2\n227     0\n228     3\n229     4\n230     1\n231     0\n232     3\n233     4\n234     2\n235     0\n236     3\n237     2\n238     2\n239     3\n240     4\n241     0\n242     2\n243     4\n244     4\n245     1\n246     0\n247     0\n248     3\n249     3\n250     0\n251     4\n252     1\n253     2\n254     4\n255     4\n256     1\n257     1\n258     1\n259     3\n260     0\n261     4\n262     1\n263     4\n264     0\n265     2\n266     4\n267     0\n268     1\n269     1\n270     3\n271     4\n272     2\n273     1\n274     0\n275     3\n276     0\n277     4\n278     4\n279     4\n280     0\n281     0\n282     2\n283     2\n284     3\n285     2\n286     2\n287     0\n288     3\n289     0\n290     1\n291     1\n292     3\n293     2\n294     0\n295     1\n296     4\n297     3\n298     1\n299     1\n300     0\n301     0\n302     4\n303     3\n304     2\n305     3\n306     1\n307     1\n308     3\n309     1\n310     1\n311     1\n312     3\n313     0\n314     2\n315     0\n316     3\n317     3\n318     1\n319     1\n320     0\n321     0\n322     3\n323     2\n324     4\n325     1\n326     4\n327     3\n328     4\n329     1\n330     0\n331     1\n332     1\n333     2\n334     1\n335     0\n336     1\n337     1\n338     2\n339     1\n340     2\n341     1\n342     3\n343     3\n344     3\n345     3\n346     3\n347     2\n348     4\n349     2\n350     2\n351     1\n352     4\n353     2\n354     4\n355     2\n356     1\n357     3\n358     0\n359     0\n360     4\n361     3\n362     4\n363     4\n364     0\n365     0\n366     1\n367     4\n368     0\n369     1\n370     1\n371     4\n372     2\n373     1\n374     4\n375     1\n376     0\n377     1\n378     4\n379     0\n380     1\n381     4\n382     2\n383     3\n384     0\n385     2\n386     4\n387     3\n388     0\n389     3\n390     1\n391     0\n392     2\n393     1\n394     4\n395     0\n396     0\n397     3\n398     2\n399     3\n400     2\n401     2\n402     2\n403     2\n404     2\n405     2\n406     0\n407     4\n408     0\n409     4\n410     0\n411     4\n412     1\n413     4\n414     2\n415     2\n416     3\n417     3\n418     3\n419     2\n420     0\n421     0\n422     0\n423     4\n424     4\n425     0\n426     3\n427     3\n428     0\n429     2\n430     1\n431     2\n432     3\n433     4\n434     1\n435     1\n436     4\n437     4\n438     1\n439     2\n440     2\n441     2\n442     0\n443     3\n444     2\n445     1\n446     2\n447     1\n448     4\n449     1\n450     4\n451     3\n452     1\n453     1\n454     2\n455     0\n456     1\n457     3\n458     2\n459     0\n460     1\n461     2\n462     1\n463     3\n464     2\n465     4\n466     4\n467     1\n468     0\n469     4\n470     0\n471     2\n472     4\n473     3\n474     2\n475     3\n476     2\n477     4\n478     0\n479     4\n480     4\n481     4\n482     2\n483     2\n484     1\n485     4\n486     1\n487     1\n488     2\n489     4\n490     3\n491     0\n492     1\n493     1\n494     2\n495     4\n496     1\n497     0\n498     3\n499     0\n       ..\n809     1\n810     0\n811     2\n812     2\n813     4\n814     2\n815     4\n816     2\n817     3\n818     4\n819     4\n820     3\n821     2\n822     4\n823     4\n824     4\n825     4\n826     4\n827     3\n828     0\n829     1\n830     4\n831     4\n832     4\n833     0\n834     2\n835     1\n836     2\n837     2\n838     4\n839     1\n840     2\n841     4\n842     3\n843     4\n844     2\n845     0\n846     4\n847     0\n848     3\n849     1\n850     4\n851     0\n852     4\n853     3\n854     3\n855     4\n856     1\n857     1\n858     4\n859     4\n860     4\n861     3\n862     3\n863     4\n864     3\n865     3\n866     3\n867     1\n868     2\n869     4\n870     0\n871     3\n872     4\n873     2\n874     3\n875     4\n876     4\n877     0\n878     0\n879     1\n880     3\n881     0\n882     3\n883     2\n884     4\n885     4\n886     3\n887     1\n888     4\n889     1\n890     0\n891     0\n892     4\n893     2\n894     2\n895     4\n896     2\n897     0\n898     2\n899     4\n900     2\n901     0\n902     3\n903     1\n904     3\n905     1\n906     3\n907     3\n908     4\n909     2\n910     4\n911     1\n912     4\n913     1\n914     1\n915     1\n916     0\n917     1\n918     4\n919     1\n920     4\n921     3\n922     2\n923     4\n924     4\n925     1\n926     4\n927     2\n928     2\n929     2\n930     4\n931     4\n932     1\n933     0\n934     3\n935     3\n936     2\n937     1\n938     0\n939     1\n940     4\n941     1\n942     3\n943     3\n944     1\n945     3\n946     4\n947     0\n948     0\n949     2\n950     1\n951     0\n952     3\n953     0\n954     0\n955     1\n956     2\n957     0\n958     3\n959     1\n960     1\n961     0\n962     0\n963     2\n964     1\n965     1\n966     1\n967     2\n968     3\n969     3\n970     0\n971     4\n972     1\n973     3\n974     0\n975     3\n976     4\n977     0\n978     2\n979     0\n980     0\n981     4\n982     0\n983     3\n984     2\n985     3\n986     0\n987     1\n988     2\n989     0\n990     2\n991     1\n992     3\n993     0\n994     0\n995     4\n996     0\n997     0\n998     0\n999     2\n1000    3\n1001    3\n1002    0\n1003    1\n1004    0\n1005    1\n1006    4\n1007    4\n1008    4\n1009    1\n1010    3\n1011    0\n1012    0\n1013    1\n1014    0\n1015    0\n1016    2\n1017    0\n1018    0\n1019    3\n1020    2\n1021    2\n1022    1\n1023    4\n1024    4\n1025    0\n1026    0\n1027    4\n1028    3\n1029    2\n1030    4\n1031    4\n1032    3\n1033    1\n1034    3\n1035    1\n1036    2\n1037    3\n1038    2\n1039    1\n1040    3\n1041    1\n1042    0\n1043    3\n1044    4\n1045    4\n1046    0\n1047    1\n1048    0\n1049    1\n1050    4\n1051    0\n1052    4\n1053    3\n1054    4\n1055    3\n1056    0\n1057    1\n1058    4\n1059    1\n1060    2\n1061    0\n1062    4\n1063    4\n1064    4\n1065    4\n1066    3\n1067    2\n1068    1\n1069    2\n1070    1\n1071    3\n1072    1\n1073    1\n1074    0\n1075    1\n1076    3\n1077    2\n1078    2\n1079    4\n1080    3\n1081    3\n1082    3\n1083    4\n1084    3\n1085    3\n1086    0\n1087    1\n1088    0\n1089    2\n1090    2\n1091    0\n1092    4\n1093    1\n1094    2\n1095    2\n1096    3\n1097    0\n1098    2\n1099    1\n1100    0\n1101    0\n1102    4\n1103    2\n1104    3\n1105    0\n1106    1\n1107    0\n1108    1\n1109    1\n1110    2\n1111    3\n1112    2\n1113    2\n1114    0\n1115    1\n1116    4\n1117    0\n1118    0\n1119    0\n1120    3\n1121    3\n1122    1\n1123    4\n1124    0\n1125    1\n1126    0\n1127    1\n1128    4\n1129    3\n1130    1\n1131    1\n1132    3\n1133    1\n1134    0\n1135    4\n1136    3\n1137    2\n1138    3\n1139    3\n1140    4\n1141    4\n1142    2\n1143    1\n1144    2\n1145    2\n1146    0\n1147    0\n1148    2\n1149    3\n1150    0\n1151    2\n1152    0\n1153    0\n1154    4\n1155    3\n1156    0\n1157    4\n1158    0\n1159    2\n1160    2\n1161    1\n1162    0\n1163    1\n1164    0\n1165    4\n1166    3\n1167    2\n1168    3\n1169    2\n1170    2\n1171    2\n1172    4\n1173    0\n1174    4\n1175    4\n1176    0\n1177    0\n1178    1\n1179    4\n1180    2\n1181    1\n1182    4\n1183    4\n1184    1\n1185    2\n1186    0\n1187    2\n1188    4\n1189    1\n1190    0\n1191    0\n1192    3\n1193    2\n1194    2\n1195    0\n1196    1\n1197    3\n1198    4\n1199    3\n1200    4\n1201    2\n1202    4\n1203    0\n1204    0\n1205    1\n1206    0\n1207    1\n1208    2\n1209    0\n1210    2\n1211    0\n1212    4\n1213    3\n1214    1\n1215    1\n1216    4\n1217    2\n1218    1\n1219    3\n1220    3\n1221    2\n1222    1\n1223    4\n1224    4\n1225    0\n1226    3\n1227    3\n1228    4\n1229    2\n1230    4\n1231    2\n1232    0\n1233    4\n1234    1\n1235    4\n1236    0\n1237    3\n1238    4\n1239    3\n1240    2\n1241    1\n1242    2\n1243    2\n1244    3\n1245    4\n1246    3\n1247    3\n1248    0\n1249    0\n1250    0\n1251    4\n1252    3\n1253    2\n1254    2\n1255    1\n1256    4\n1257    4\n1258    4\n1259    1\n1260    3\n1261    3\n1262    1\n1263    4\n1264    3\n1265    1\n1266    1\n1267    2\n1268    3\n1269    1\n1270    4\n1271    0\n1272    0\n1273    0\n1274    2\n1275    3\n1276    3\n1277    0\n1278    3\n1279    0\n1280    4\n1281    3\n1282    3\n1283    4\n1284    2\n1285    0\n1286    1\n1287    0\n1288    1\n1289    0\n1290    0\n1291    1\n1292    2\n1293    1\n1294    3\n1295    1\n1296    3\n1297    2\n1298    1\n1299    0\n1300    4\n1301    0\n1302    1\n1303    0\n1304    2\n1305    1\n1306    0\n1307    2\n1308    0\nName: Fare_bin_id, Length: 1309, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将票价划分为5组,qcut将数据分组\n",
    "df['Fare_bin'] = pd.qcut(df['Fare'], 5)\n",
    "df[\"Fare_bin\"].unique()\n",
    "# factorize方法将标称型类别变量映射为数值型类别变量，返回值为一个二元组\n",
    "df['Fare_bin_id'] = pd.factorize(df['Fare_bin'])[0]\n",
    "df['Fare_bin_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([              0,               1,               2,               3,               4,               0,               1,               2,               3,               4,\n       ...\n                 'Sex',         'SibSp',      'Survived',        'Ticket',         'Title',  'Group_Ticket', 'Group_Ticket2',     'Fare_mean',      'Fare_bin',   'Fare_bin_id'],\n      dtype='object', length=852)\n"
     ]
    }
   ],
   "source": [
    "fare_bin_dummies_df = pd.get_dummies(df['Fare_bin_id'])\n",
    "df = pd.concat([fare_bin_dummies_df, df], axis=1)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
